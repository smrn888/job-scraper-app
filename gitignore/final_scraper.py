import time
import random
import re
import os
import cv2
import numpy as np
import requests
import urllib.parse
from datetime import datetime
from bs4 import BeautifulSoup
import pandas as pd
import gspread
from oauth2client.service_account import ServiceAccountCredentials

from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.common.action_chains import ActionChains
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from selenium.common.exceptions import TimeoutException, NoSuchElementException


class FixedJobScraper:
    def __init__(self, email, password, headless=False):
        self.email = email
        self.password = password
        self.jobs = []
        self.setup_browser(headless)

    # ğŸ§­ Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ù…Ø±ÙˆØ±Ú¯Ø±
    def setup_browser(self, headless):
        chrome_options = Options()
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        chrome_options.add_experimental_option('prefs', {'profile.default_content_setting_values.notifications': 2})
        if headless:
            chrome_options.add_argument('--headless=new')

        service = Service(executable_path='chromedriver.exe')
        self.driver = webdriver.Chrome(service=service, options=chrome_options)
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")

    # âœ… Ù…Ø±Ø­Ù„Ù‡ Ù„Ø§Ú¯ÛŒÙ† Ø¨Ù‡ JobVision (Ø¨Ø§ Ú©Ù¾Ú†Ø§)
    def login_to_jobvision(self):
        print("\n========================")
        print("LOGIN TO JOBVISION")
        print("========================")

        self.driver.get("https://account.jobvision.ir/Candidate")
        WebDriverWait(self.driver, 20).until(EC.presence_of_element_located((By.NAME, "Username")))

        # Ø§ÛŒÙ…ÛŒÙ„
        email_input = self.driver.find_element(By.NAME, "Username")
        email_input.send_keys(self.email)
        email_input.send_keys(Keys.ESCAPE)
        time.sleep(0.5)

        continue_btn = self.driver.find_element(By.CSS_SELECTOR, "a.btn.btn-primary")
        self.driver.execute_script("arguments[0].click();", continue_btn)
        time.sleep(2)

        # Ø­Ù„ Ú©Ù¾Ú†Ø§ ØªØ§ Ù…ÙˆÙÙ‚ÛŒØª
        self.solve_arcaptcha_loop()

        # Ù¾Ø³ÙˆØ±Ø¯
        password_input = WebDriverWait(self.driver, 15).until(
            EC.presence_of_element_located((By.NAME, "Password"))
        )
        password_input.clear()
        password_input.send_keys(self.password)
        time.sleep(0.5)

        # ØµØ¨Ø± Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ†Ú©Ù‡ Ø¯Ú©Ù…Ù‡ ÙˆØ±ÙˆØ¯ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´ÙˆØ¯
        try:
            login_button = WebDriverWait(self.driver, 10).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, "button.btn.btn-primary"))
            )
        except TimeoutException:
            try:
                login_button = WebDriverWait(self.driver, 5).until(
                    EC.element_to_be_clickable((By.CSS_SELECTOR, "a.btn.btn-primary"))
                )
            except TimeoutException:
                raise Exception("âŒ Ø¯Ú©Ù…Ù‡ ÙˆØ±ÙˆØ¯ Ù¾ÛŒØ¯Ø§ Ù†Ø´Ø¯!")

        self.driver.execute_script("arguments[0].scrollIntoView(true);", login_button)
        time.sleep(0.2)
        self.driver.execute_script("arguments[0].click();", login_button)
        print("ğŸ” Ø±Ù…Ø² ÙˆØ§Ø±Ø¯ Ø´Ø¯ Ùˆ Ø±ÙˆÛŒ ÙˆØ±ÙˆØ¯ Ú©Ù„ÛŒÚ© Ø´Ø¯.")

        try:
            WebDriverWait(self.driver, 15).until(
                EC.url_contains("jobvision.ir")
            )
            print("ğŸ‰ ÙˆØ±ÙˆØ¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯ âœ…")
        except TimeoutException:
            print("âš ï¸ ÙˆØ±ÙˆØ¯ Ù…Ù…Ú©Ù† Ø§Ø³Øª Ù…ÙˆÙÙ‚ Ù†Ø´Ø¯Ù‡ Ø¨Ø§Ø´Ø¯. URL ÙØ¹Ù„ÛŒ:", self.driver.current_url)

    # ğŸ§  Ø­Ù„ Ú©Ù¾Ú†Ø§ÛŒ ARCaptcha
    def solve_arcaptcha(self):
        """
        Ø­Ù„ Ú©Ù¾Ú†Ø§ÛŒ Ù¾Ø§Ø²Ù„ÛŒ ARCaptcha
        Returns True if successful, False otherwise
        """
        try:
            # Ù…Ù†ØªØ¸Ø± Ø¨Ù…Ø§Ù† ØªØ§ iframe Ú©Ù¾Ú†Ø§ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø´ÙˆØ¯
            WebDriverWait(self.driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, "iframe[src*='arcaptcha']"))
            )
            
            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† iframe Ú©Ù¾Ú†Ø§
            captcha_iframe = self.driver.find_element(By.CSS_SELECTOR, "iframe[src*='arcaptcha']")
            self.driver.switch_to.frame(captcha_iframe)
            time.sleep(2)

            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† ØªØµØ§ÙˆÛŒØ± Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ùˆ Ù‚Ø·Ø¹Ù‡ Ù¾Ø§Ø²Ù„
            bg_img = self.driver.find_element(By.CSS_SELECTOR, "img.captcha-bg")
            piece_img = self.driver.find_element(By.CSS_SELECTOR, "img.captcha-piece")
            
            bg_url = bg_img.get_attribute('src')
            piece_url = piece_img.get_attribute('src')

            # Ø¯Ø§Ù†Ù„ÙˆØ¯ ØªØµØ§ÙˆÛŒØ±
            bg = self.download_image(bg_url)
            piece = self.download_image(piece_url)

            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´Ú©Ø§Ù
            gap_x = self.find_gap_position(bg, piece)
            print(f"ğŸ¯ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´Ú©Ø§Ù: {gap_x}px")

            # Ù¾ÛŒØ¯Ø§ Ú©Ø±Ø¯Ù† slider
            slider = self.driver.find_element(By.CSS_SELECTOR, ".slider-button")
            
            # Ú©Ø´ÛŒØ¯Ù† slider Ø¨Ù‡ Ù…ÙˆÙ‚Ø¹ÛŒØª Ù…Ù†Ø§Ø³Ø¨
            actions = ActionChains(self.driver)
            actions.click_and_hold(slider).perform()
            time.sleep(0.2)
            
            # Ø­Ø±Ú©Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø·Ø¨ÛŒØ¹ÛŒâ€ŒØªØ± (Ø¨Ø§ ØªÚ©Ù‡â€ŒÙ‡Ø§ÛŒ Ú©ÙˆÚ†Ú©)
            move_distance = gap_x
            steps = random.randint(15, 25)
            for i in range(steps):
                step_size = move_distance / steps
                actions.move_by_offset(step_size, random.uniform(-2, 2)).perform()
                time.sleep(random.uniform(0.01, 0.03))
            
            time.sleep(0.3)
            actions.release().perform()
            
            # Ø¨Ø±Ú¯Ø´Øª Ø¨Ù‡ Ù…Ø­ØªÙˆØ§ÛŒ Ø§ØµÙ„ÛŒ
            self.driver.switch_to.default_content()
            time.sleep(2)
            
            # Ø¨Ø±Ø±Ø³ÛŒ Ù…ÙˆÙÙ‚ÛŒØª: Ø¢ÛŒØ§ Ú©Ù¾Ú†Ø§ Ø­Ù„ Ø´Ø¯Ù‡ØŸ
            try:
                WebDriverWait(self.driver, 5).until(
                    EC.presence_of_element_located((By.NAME, "Password"))
                )
                return True
            except TimeoutException:
                return False
                
        except Exception as e:
            print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± Ø­Ù„ Ú©Ù¾Ú†Ø§: {e}")
            try:
                self.driver.switch_to.default_content()
            except:
                pass
            return False

    # ğŸ§  Ø­Ù„ Ú©Ù¾Ú†Ø§ÛŒ ARCaptcha Ø¨Ø§ ØªÙ„Ø§Ø´ Ù…Ú©Ø±Ø±
    def solve_arcaptcha_loop(self, max_attempts=5):
        for attempt in range(1, max_attempts + 1):
            print(f"ğŸ§  ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø­Ù„ Ú©Ù¾Ú†Ø§... (Ù…Ø±ØªØ¨Ù‡ {attempt})")
            try:
                if self.solve_arcaptcha():
                    print("âœ… Ú©Ù¾Ú†Ø§ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø­Ù„ Ø´Ø¯")
                    return
            except Exception as e:
                print(f"âš ï¸ Ø®Ø·Ø§ Ø¯Ø± ØªÙ„Ø§Ø´ {attempt}: {e}")

            # Ø§Ú¯Ù‡ Ù…ÙˆÙÙ‚ Ù†Ø¨ÙˆØ¯ØŒ Ø±ÛŒÙØ±Ø´ Ú©Ù¾Ú†Ø§ ÛŒØ§ ØµÙØ­Ù‡
            time.sleep(2)
            try:
                # ØªÙ„Ø§Ø´ Ø¨Ø±Ø§ÛŒ Ø±ÛŒÙØ±Ø´ Ú©Ù¾Ú†Ø§
                refresh_btn = self.driver.find_element(By.CSS_SELECTOR, "#challenge button")
                self.driver.execute_script("arguments[0].click();", refresh_btn)
                time.sleep(2)
            except NoSuchElementException:
                # Ø§Ú¯Ù‡ Ø¯Ú©Ù…Ù‡ refresh Ù†Ø¨ÙˆØ¯ØŒ ØµÙØ­Ù‡ Ø±Ùˆ Ø¯ÙˆØ¨Ø§Ø±Ù‡ Ù„ÙˆØ¯ Ú©Ù†
                print("ğŸ”„ Ø±ÙØ±Ø´ ØµÙØ­Ù‡...")
                self.driver.refresh()
                time.sleep(4)

                # Ø¨Ø±Ø±Ø³ÛŒ Ø¯ÙˆØ¨Ø§Ø±Ù‡: Ø¢ÛŒØ§ ÙÛŒÙ„Ø¯ Ø§ÛŒÙ…ÛŒÙ„ Ø¨Ø±Ú¯Ø´ØªÙ‡ØŸ
                try:
                    email_input = WebDriverWait(self.driver, 5).until(
                        EC.presence_of_element_located((By.NAME, "Username"))
                    )
                    email_input.clear()
                    email_input.send_keys(self.email)
                    email_input.send_keys(Keys.ESCAPE)
                    time.sleep(0.5)

                    continue_btn = self.driver.find_element(By.CSS_SELECTOR, "a.btn.btn-primary")
                    self.driver.execute_script("arguments[0].click();", continue_btn)
                    time.sleep(2)
                except TimeoutException:
                    pass

        raise Exception("âŒ Ø­Ù„ Ú©Ù¾Ú†Ø§ Ø¨Ø¹Ø¯ Ø§Ø² Ú†Ù†Ø¯ ØªÙ„Ø§Ø´ Ù†Ø§Ù…ÙˆÙÙ‚ Ø¨ÙˆØ¯.")

    # ğŸ“¥ Ø¯Ø§Ù†Ù„ÙˆØ¯ Ø¹Ú©Ø³
    def download_image(self, url):
        r = requests.get(url)
        arr = np.asarray(bytearray(r.content), dtype=np.uint8)
        return cv2.imdecode(arr, cv2.IMREAD_COLOR)

    # ğŸ” ØªØ´Ø®ÛŒØµ Ù…ÙˆÙ‚Ø¹ÛŒØª Ø´Ú©Ø§Ù Ù¾Ø§Ø²Ù„ Ø¨Ø§ Canny
    def find_gap_position(self, bg, piece):
        bg_gray = cv2.cvtColor(bg, cv2.COLOR_BGR2GRAY)
        piece_gray = cv2.cvtColor(piece, cv2.COLOR_BGR2GRAY)
        bg_gray = cv2.GaussianBlur(bg_gray, (3, 3), 0)
        piece_gray = cv2.GaussianBlur(piece_gray, (3, 3), 0)
        bg_edges = cv2.Canny(bg_gray, 100, 200)
        piece_edges = cv2.Canny(piece_gray, 100, 200)
        res = cv2.matchTemplate(bg_edges, piece_edges, cv2.TM_CCOEFF_NORMED)
        _, max_val, _, max_loc = cv2.minMaxLoc(res)
        return max_loc[0]

    # ğŸ“ Ø§Ø³Ú©Ø±Ù¾ÛŒÙ†Ú¯ Ø¨Ø¹Ø¯ Ø§Ø² ÙˆØ±ÙˆØ¯
    def scrape_jobvision(self, keywords=['Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ', 'machine learning']):
        print("\n========================")
        print("SCRAPING JOBVISION")
        print("========================")

        for keyword in keywords:
            encoded = urllib.parse.quote(keyword)
            url = f"https://jobvision.ir/jobs/keyword/{encoded}"
            self.driver.get(url)
            time.sleep(3)

            for _ in range(3):
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)

            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            job_links = soup.find_all('a', href=lambda x: x and '/jobs/' in x)

            for link in job_links:
                href = link['href']
                if not href.startswith('http'):
                    href = "https://jobvision.ir" + href

                title = link.get_text(strip=True)
                if not title:
                    continue

                self.jobs.append({
                    'date_added': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    'title': title,
                    'company': 'N/A',
                    'location': 'N/A',
                    'requirements': 'N/A',
                    'salary': 'N/A',
                    'contract_type': 'N/A',
                    'working_hours': 'N/A',
                    'link': href,
                    'source': 'JobVision'
                })
            print(f"âœ… {len(self.jobs)} job(s) found so far.")

    # ğŸ’¾ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± CSV
    def save_to_csv_append(self, filename='jobs.csv'):
        if not self.jobs:
            return
        df_new = pd.DataFrame(self.jobs)
        if os.path.exists(filename):
            df_old = pd.read_csv(filename, encoding='utf-8-sig')
            combined = pd.concat([df_old, df_new], ignore_index=True).drop_duplicates('link')
            combined.to_csv(filename, index=False, encoding='utf-8-sig')
        else:
            df_new.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ {len(self.jobs)} Ø´ØºÙ„ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø± {filename}")

    def close(self):
        self.driver.quit()


# ğŸ Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡
if __name__ == "__main__":
    EMAIL = "your_email@example.com"  # Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒØ¯
    PASSWORD = "your_password"  # Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ† Ú©Ù†ÛŒØ¯

    scraper = FixedJobScraper(email=EMAIL, password=PASSWORD)
    try:
        scraper.login_to_jobvision()
        scraper.scrape_jobvision(keywords=["Ù‡ÙˆØ´ Ù…ØµÙ†ÙˆØ¹ÛŒ", "machine learning"])
        scraper.save_to_csv_append("jobs.csv")
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø§: {e}")
    finally:
        scraper.close()